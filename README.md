# Akamai Crawler Project

Welcome to my Crawler Project! This project aims to provide a simple web crawler built using Scrapy, a simple 
and flexible web scraping framework in Python.

## What is Scrapy?

Scrapy is an open-source web crawling framework written in Python. It allows you to extract data from websites, automate
the process of gathering information, and perform tasks like scraping, crawling, and parsing web pages.

## Dependencies

To run this Scrapy project, you'll need the following dependencies:

- Python 
- Scrapy

## Installation

Before running the Scrapy crawler, make sure you have Python installed on your system. You can install Scrapy and 
other required dependencies using pip:

```bash
pip install scrapy
```

## Usage

To run the Scrapy crawler, execute the `main.py` script provided in the project. The crawler will start crawling the 
specified website and generate reports containing extracted data.

```bash
python main.py
```
